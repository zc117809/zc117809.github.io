<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.5"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><link rel="stylesheet" type="text/css" href="https://unpkg.com/gitalk/dist/gitalk.css?v=2.0.5"><title>srapy的高级使用 | Simple</title><meta name="generator" content="Hexo 4.2.1"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">srapy的高级使用</h1><a id="logo" href="/.">Simple</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">srapy的高级使用</h1><div class="post-meta"><a href="/2019/11/08/srapy%E7%9A%84%E9%AB%98%E7%BA%A7%E4%BD%BF%E7%94%A8/#comments" class="comment-count"></a><p><span class="date">Nov 08, 2019</span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h2 id="srapy的高级使用"><a href="#srapy的高级使用" class="headerlink" title="srapy的高级使用"></a>srapy的高级使用</h2><h2 id="1-自动给抽屉点赞"><a href="#1-自动给抽屉点赞" class="headerlink" title="1 自动给抽屉点赞"></a>1 自动给抽屉点赞</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">bro=webdriver.Chrome(executable_path=<span class="string">'./chromedriver.exe'</span>)</span><br><span class="line">bro.implicitly_wait(<span class="number">10</span>)</span><br><span class="line">bro.get(<span class="string">'https://dig.chouti.com/'</span>)</span><br><span class="line"></span><br><span class="line">login_b=bro.find_element_by_id(<span class="string">'login_btn'</span>)</span><br><span class="line">print(login_b)</span><br><span class="line">login_b.click()</span><br><span class="line"></span><br><span class="line">username=bro.find_element_by_name(<span class="string">'phone'</span>)</span><br><span class="line">username.send_keys(<span class="string">'18953675221'</span>)</span><br><span class="line">password=bro.find_element_by_name(<span class="string">'password'</span>)</span><br><span class="line">password.send_keys(<span class="string">'lqz123'</span>)</span><br><span class="line"></span><br><span class="line">button=bro.find_element_by_css_selector(<span class="string">'button.login-btn'</span>)</span><br><span class="line">button.click()</span><br><span class="line"><span class="comment"># 可能有验证码，手动操作一下</span></span><br><span class="line">time.sleep(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">my_cookie=bro.get_cookies()  <span class="comment"># 列表</span></span><br><span class="line">print(my_cookie)</span><br><span class="line">bro.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个cookie不是一个字典，不能直接给requests使用，需要转一下</span></span><br><span class="line">cookie=&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> my_cookie:</span><br><span class="line">    cookie[item[<span class="string">'name'</span>]]=item[<span class="string">'value'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Referer'</span>: <span class="string">'https://dig.chouti.com/'</span>&#125;</span><br><span class="line"><span class="comment"># ret = requests.get('https://dig.chouti.com/',headers=headers)</span></span><br><span class="line"><span class="comment"># print(ret.text)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ret=requests.get(<span class="string">'https://dig.chouti.com/top/24hr?_=1596677637670'</span>,headers=headers)</span><br><span class="line">print(ret.json())</span><br><span class="line">ll=[]</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> ret.json()[<span class="string">'data'</span>]:</span><br><span class="line">    ll.append(item[<span class="string">'id'</span>])</span><br><span class="line"></span><br><span class="line">print(ll)</span><br><span class="line"><span class="keyword">for</span> id <span class="keyword">in</span> ll:</span><br><span class="line">    ret=requests.post(<span class="string">' https://dig.chouti.com/link/vote'</span>,headers=headers,cookies=cookie,data=&#123;<span class="string">'linkId'</span>:id&#125;)</span><br><span class="line">    print(ret.text)</span><br><span class="line"></span><br><span class="line"><span class="string">'https://dig.chouti.com/comments/create'</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">content: 说的号</span></span><br><span class="line"><span class="string">linkId: 29829529</span></span><br><span class="line"><span class="string">parentId: 0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>

<h2 id="3-scrapy的请求传参"><a href="#3-scrapy的请求传参" class="headerlink" title="3 scrapy的请求传参"></a>3 scrapy的请求传参</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把要传递的数据放到meta中</span></span><br><span class="line"><span class="keyword">yield</span> Request(urlmeta=&#123;<span class="string">'item'</span>:item&#125;)</span><br><span class="line"><span class="comment"># 在response对象中取出来</span></span><br><span class="line">item=response.meta.get(<span class="string">'item'</span>)</span><br></pre></td></tr></table></figure>



<h2 id="4-提升scrapy爬取数据的效率"><a href="#4-提升scrapy爬取数据的效率" class="headerlink" title="4 提升scrapy爬取数据的效率"></a>4 提升scrapy爬取数据的效率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- 在配置文件中进行相关的配置即可:(默认还有一套setting)</span><br><span class="line"><span class="comment">#1 增加并发：</span></span><br><span class="line">默认scrapy开启的并发线程为<span class="number">32</span>个，可以适当进行增加。在settings配置文件中修改CONCURRENT_REQUESTS = <span class="number">100</span>值为<span class="number">100</span>,并发设置成了为<span class="number">100</span>。</span><br><span class="line"><span class="comment">#2 降低日志级别：</span></span><br><span class="line">在运行scrapy时，会有大量日志信息的输出，为了减少CPU的使用率。可以设置log输出信息为INFO或者ERROR即可。在配置文件中编写：LOG_LEVEL = ‘INFO’</span><br><span class="line"><span class="comment"># 3 禁止cookie：</span></span><br><span class="line">如果不是真的需要cookie，则在scrapy爬取数据时可以禁止cookie从而减少CPU的使用率，提升爬取效率。在配置文件中编写：COOKIES_ENABLED = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 4禁止重试：</span></span><br><span class="line">对失败的HTTP进行重新请求（重试）会减慢爬取速度，因此可以禁止重试。在配置文件中编写：RETRY_ENABLED = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 5 减少下载超时：</span></span><br><span class="line">如果对一个非常慢的链接进行爬取，减少下载超时可以能让卡住的链接快速被放弃，从而提升效率。在配置文件中进行编写：DOWNLOAD_TIMEOUT = <span class="number">10</span> 超时时间为<span class="number">10</span>s</span><br></pre></td></tr></table></figure>



<h2 id="5-scrapy的中间件（下载中间件）"><a href="#5-scrapy的中间件（下载中间件）" class="headerlink" title="5 scrapy的中间件（下载中间件）"></a>5 scrapy的中间件（下载中间件）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1 都写在middlewares.py</span></span><br><span class="line"><span class="comment"># 2 爬虫中间件</span></span><br><span class="line"><span class="comment"># 3 下载中间件</span></span><br><span class="line"><span class="comment"># 4 要生效，一定要配置，配置文件</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载中间件</span></span><br><span class="line">-process_request：返回不同的对象，后续处理不同（加代理...）</span><br><span class="line">  		<span class="comment"># 1 更换请求头</span></span><br><span class="line">        <span class="comment"># print(type(request.headers))</span></span><br><span class="line">        <span class="comment"># print(request.headers)</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># from scrapy.http.headers import Headers</span></span><br><span class="line">        <span class="comment"># request.headers['User-Agent']=''</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2 加cookie ---cookie池</span></span><br><span class="line">        <span class="comment"># 假设你你已经搭建好cookie 池了，</span></span><br><span class="line">        <span class="comment"># print('00000--',request.cookies)</span></span><br><span class="line">        <span class="comment"># request.cookies=&#123;'username':'asdfasdf'&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3 加代理</span></span><br><span class="line">        <span class="comment"># print(request.meta)</span></span><br><span class="line">        <span class="comment"># request.meta['download_timeout'] = 20</span></span><br><span class="line">        <span class="comment"># request.meta["proxy"] = 'http://27.188.62.3:8060'</span></span><br><span class="line">-process_response：返回不同的对象，后续处理不同</span><br><span class="line">- process_exception</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_exception</span><span class="params">(self, request, exception, spider)</span>:</span></span><br><span class="line">        print(<span class="string">'xxxx'</span>)</span><br><span class="line">        <span class="comment"># 不允许直接改url</span></span><br><span class="line">        <span class="comment"># request.url='https://www.baidu.com'</span></span><br><span class="line">        <span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line">        request=Request(url=<span class="string">'https://www.baidu.com'</span>,callback=spider.parser)</span><br><span class="line">        <span class="keyword">return</span> request</span><br></pre></td></tr></table></figure>



<h2 id="6-selenium在scrapy中的使用流程"><a href="#6-selenium在scrapy中的使用流程" class="headerlink" title="6 selenium在scrapy中的使用流程"></a>6 selenium在scrapy中的使用流程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 当前爬虫用的selenium是同一个</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 在爬虫中初始化webdriver对象</span></span><br><span class="line">    <span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">CnblogSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">        name = <span class="string">'cnblog'</span></span><br><span class="line">        ...</span><br><span class="line"> bro=webdriver.Chrome(executable_path=<span class="string">'../chromedriver.exe'</span>)</span><br><span class="line"><span class="comment"># 2 在中间件中使用（process_request）</span></span><br><span class="line">spider.bro.get(<span class="string">'https://dig.chouti.com/'</span>)   response=HtmlResponse(url=<span class="string">'https://dig.chouti.com/'</span>,body=spider.bro.page_source.encode(<span class="string">'utf-8'</span>),request=request)</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 3 在爬虫中关闭</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self, reason)</span>:</span></span><br><span class="line">        print(<span class="string">"我结束了"</span>)</span><br><span class="line">        self.bro.close()</span><br></pre></td></tr></table></figure>



<h2 id="7-去重规则源码分析"><a href="#7-去重规则源码分析" class="headerlink" title="7 去重规则源码分析"></a>7 去重规则源码分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 详见代码</span></span><br></pre></td></tr></table></figure>



<h2 id="8-分布式爬虫（scrapy-redis）"><a href="#8-分布式爬虫（scrapy-redis）" class="headerlink" title="8 分布式爬虫（scrapy-redis）"></a>8 分布式爬虫（scrapy-redis）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1 pip3 install scrapy-redis</span></span><br><span class="line"><span class="comment"># 2 原来继承Spider，现在继承RedisSpider</span></span><br><span class="line"><span class="comment"># 3 不能写start_urls = ['https:/www.cnblogs.com/']</span></span><br><span class="line"><span class="comment"># 4 需要写redis_key = 'myspider:start_urls'</span></span><br><span class="line"><span class="comment"># 5 setting中配置：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># redis的连接</span></span><br><span class="line">REDIS_HOST = <span class="string">'localhost'</span>                            <span class="comment"># 主机名</span></span><br><span class="line">REDIS_PORT = <span class="number">6379</span>                                   <span class="comment"># 端口</span></span><br><span class="line">	<span class="comment"># 使用scrapy-redis的去重</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></span><br><span class="line"><span class="comment"># 使用scrapy-redis的Scheduler</span></span><br><span class="line"><span class="comment"># 分布式爬虫的配置</span></span><br><span class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></span><br><span class="line"><span class="comment"># 持久化的可以配置，也可以不配置</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">299</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 9现在要让爬虫运行起来，需要去redis中以myspider:start_urls为key，插入一个起始地址lpush myspider:start_urls https://www.cnblogs.com/</span></span><br></pre></td></tr></table></figure>



<h2 id="9-破解知乎登陆-js逆向和解密"><a href="#9-破解知乎登陆-js逆向和解密" class="headerlink" title="9 破解知乎登陆(js逆向和解密)"></a>9 破解知乎登陆(js逆向和解密)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line">client_id=c3cef7c66a1843f8b3a9e6a1e3160e20&amp;</span><br><span class="line">grant_type=password&amp;</span><br><span class="line">timestamp=<span class="number">1596702006088</span>&amp;</span><br><span class="line">source=com.zhihu.web&amp;</span><br><span class="line">signature=eac4a6c461f9edf86ef33ef950c7b6aa426dbb39&amp;</span><br><span class="line">username=%<span class="number">2</span>B86liuqingzheng&amp;</span><br><span class="line">password=<span class="number">1111111</span>&amp;</span><br><span class="line">captcha=&amp;</span><br><span class="line">lang=en&amp;</span><br><span class="line">utm_source=&amp;</span><br><span class="line">ref_source=other_https%<span class="number">3</span>A%<span class="number">2</span>F%<span class="number">2</span>Fwww.zhihu.com%<span class="number">2</span>Fsignin%<span class="number">3</span>Fnext%<span class="number">3</span>D%<span class="number">252</span>F<span class="string">"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 破解知乎登陆</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">import requests    #请求解析库</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">import base64							  #base64解密加密库</span></span><br><span class="line"><span class="string">from PIL import Image	  			      #图片处理库</span></span><br><span class="line"><span class="string">import hmac								  #加密库</span></span><br><span class="line"><span class="string">from hashlib import sha1				  #加密库</span></span><br><span class="line"><span class="string">import time</span></span><br><span class="line"><span class="string">from urllib.parse import urlencode		  #url编码库</span></span><br><span class="line"><span class="string">import execjs							  #python调用node.js</span></span><br><span class="line"><span class="string">from http import cookiejar as cookielib</span></span><br><span class="line"><span class="string">class Spider():</span></span><br><span class="line"><span class="string">    def __init__(self):</span></span><br><span class="line"><span class="string">        self.session = requests.session()</span></span><br><span class="line"><span class="string">        self.session.cookies = cookielib.LWPCookieJar()    #使cookie可以调用save和load方法</span></span><br><span class="line"><span class="string">        self.login_page_url = 'https://www.zhihu.com/signin?next=%2F'</span></span><br><span class="line"><span class="string">        self.login_api = 'https://www.zhihu.com/api/v3/oauth/sign_in'</span></span><br><span class="line"><span class="string">        self.captcha_api = 'https://www.zhihu.com/api/v3/oauth/captcha?lang=en'</span></span><br><span class="line"><span class="string">        self.headers = &#123;</span></span><br><span class="line"><span class="string">            'user-agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.98 Safari/537.36 LBBROWSER',</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        self.captcha =''         #存验证码</span></span><br><span class="line"><span class="string">        self.signature = ''	   #存签名</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # 首次请求获取cookie</span></span><br><span class="line"><span class="string">    def get_base_cookie(self):</span></span><br><span class="line"><span class="string">        self.session.get(url=self.login_page_url, headers=self.headers)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def deal_captcha(self):</span></span><br><span class="line"><span class="string">        r = self.session.get(url=self.captcha_api, headers=self.headers)</span></span><br><span class="line"><span class="string">        r = r.json()</span></span><br><span class="line"><span class="string">        if r.get('show_captcha'):</span></span><br><span class="line"><span class="string">            while True:</span></span><br><span class="line"><span class="string">                r = self.session.put(url=self.captcha_api, headers=self.headers)</span></span><br><span class="line"><span class="string">                img_base64 = r.json().get('img_base64')</span></span><br><span class="line"><span class="string">                with open('captcha.png', 'wb') as f:</span></span><br><span class="line"><span class="string">                    f.write(base64.b64decode(img_base64))</span></span><br><span class="line"><span class="string">                captcha_img = Image.open('captcha.png')</span></span><br><span class="line"><span class="string">                captcha_img.show()</span></span><br><span class="line"><span class="string">                self.captcha = input('输入验证码:')</span></span><br><span class="line"><span class="string">                r = self.session.post(url=self.captcha_api, data=&#123;'input_text': self.captcha&#125;,</span></span><br><span class="line"><span class="string">                                      headers=self.headers)</span></span><br><span class="line"><span class="string">                if r.json().get('success'):</span></span><br><span class="line"><span class="string">                    break</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def get_signature(self):</span></span><br><span class="line"><span class="string">        # 生成加密签名</span></span><br><span class="line"><span class="string">        a = hmac.new(b'd1b964811afb40118a12068ff74a12f4', digestmod=sha1)</span></span><br><span class="line"><span class="string">        a.update(b'password')</span></span><br><span class="line"><span class="string">        a.update(b'c3cef7c66a1843f8b3a9e6a1e3160e20')</span></span><br><span class="line"><span class="string">        a.update(b'com.zhihu.web')</span></span><br><span class="line"><span class="string">        a.update(str(int(time.time() * 1000)).encode('utf-8'))</span></span><br><span class="line"><span class="string">        self.signature = a.hexdigest()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def post_login_data(self):</span></span><br><span class="line"><span class="string">        data = &#123;</span></span><br><span class="line"><span class="string">            'client_id': 'c3cef7c66a1843f8b3a9e6a1e3160e20',</span></span><br><span class="line"><span class="string">            'grant_type': 'password',</span></span><br><span class="line"><span class="string">            'timestamp': str(int(time.time() * 1000)),</span></span><br><span class="line"><span class="string">            'source': 'com.zhihu.web',</span></span><br><span class="line"><span class="string">            'signature': self.signature,</span></span><br><span class="line"><span class="string">            'username': '+8618953675221',</span></span><br><span class="line"><span class="string">            'password': '',</span></span><br><span class="line"><span class="string">            'captcha': self.captcha,</span></span><br><span class="line"><span class="string">            'lang': 'en',</span></span><br><span class="line"><span class="string">            'utm_source': '',</span></span><br><span class="line"><span class="string">            'ref_source': 'other_https://www.zhihu.com/signin?next=%2F',</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        headers = &#123;</span></span><br><span class="line"><span class="string">            'x-zse-83': '3_2.0',</span></span><br><span class="line"><span class="string">            'content-type': 'application/x-www-form-urlencoded',</span></span><br><span class="line"><span class="string">            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.98 Safari/537.36 LBBROWSER',</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        data = urlencode(data)</span></span><br><span class="line"><span class="string">        with open('zhih.js', 'rt', encoding='utf-8') as f:</span></span><br><span class="line"><span class="string">            js = execjs.compile(f.read(), cwd='node_modules')</span></span><br><span class="line"><span class="string">        data = js.call('b', data)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        r = self.session.post(url=self.login_api, headers=headers, data=data)</span></span><br><span class="line"><span class="string">        print(r.text)</span></span><br><span class="line"><span class="string">        if r.status_code == 201:</span></span><br><span class="line"><span class="string">            self.session.cookies.save('mycookie')</span></span><br><span class="line"><span class="string">            print('登录成功')</span></span><br><span class="line"><span class="string">        else:</span></span><br><span class="line"><span class="string">            print('登录失败')</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def login(self):</span></span><br><span class="line"><span class="string">        self.get_base_cookie()</span></span><br><span class="line"><span class="string">        self.deal_captcha()</span></span><br><span class="line"><span class="string">        self.get_signature()</span></span><br><span class="line"><span class="string">        self.post_login_data()</span></span><br><span class="line"><span class="string">if __name__ == '__main__':</span></span><br><span class="line"><span class="string">    zhihu_spider = Spider()</span></span><br><span class="line"><span class="string">    zhihu_spider.login()</span></span><br></pre></td></tr></table></figure>

<h2 id="10-爬虫的反扒措施"><a href="#10-爬虫的反扒措施" class="headerlink" title="10 爬虫的反扒措施"></a>10 爬虫的反扒措施</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> user-agent</span><br><span class="line"><span class="number">2</span> referer</span><br><span class="line"><span class="number">3</span> cookie（cookie池，先访问一次）</span><br><span class="line"><span class="number">4</span> 频率限制（代理池，延迟）</span><br><span class="line"><span class="number">5</span> js加密（扣出来，exjs模块指向）</span><br><span class="line"><span class="number">6</span> css加密</span><br><span class="line"><span class="number">7</span> 验证码（打码平台），半手动</span><br><span class="line"><span class="number">8</span> 图片懒加载</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">热更新：不停机更新</span><br><span class="line"></span><br><span class="line">https://www.cnblogs.com/deali/p/<span class="number">13372922.</span>html</span><br></pre></td></tr></table></figure>




</div><div class="post-copyright"><blockquote><p>原文作者: Simple</p><p>原文链接: <a href="http://yoursite.com/2019/11/08/srapy的高级使用/">http://yoursite.com/2019/11/08/srapy的高级使用/</a></p><p>版权声明: 转载请注明出处(必须保留作者署名及链接)</p></blockquote></div><div class="tags"><a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/2019/11/10/%E5%90%84%E7%A7%8D%E7%BD%91%E7%AB%99%E7%9A%84%E7%88%AC%E5%8F%96/" class="pre">各种网站的爬取</a><a href="/2019/11/07/selenium%E4%BD%BF%E7%94%A8/" class="next">selenium使用</a></div><div id="comments"><div id="container"><script type="text/javascript" src="https://unpkg.com/gitalk/dist/gitalk.min.js?v=2.0.5"></script><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=2.0.5"></script><script>var gitalk = new Gitalk({
  clientID: '0166bf5540dd89613207',
  clientSecret: '3c34e343b2e8c0f24c9e069e9874e2a661bdd7a3',
  repo: 'git@github.com:zc117809/comment.git',
  owner: 'zc117809',
  admin: ['zc117809'],
  id: md5(window.location.pathname),
  distractionFreeMode: false,
  language: 'zh-CN',
  pagerDirection: 'last'
})
gitalk.render('container')</script></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#srapy的高级使用"><span class="toc-text">srapy的高级使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-自动给抽屉点赞"><span class="toc-text">1 自动给抽屉点赞</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-scrapy的请求传参"><span class="toc-text">3 scrapy的请求传参</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-提升scrapy爬取数据的效率"><span class="toc-text">4 提升scrapy爬取数据的效率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-scrapy的中间件（下载中间件）"><span class="toc-text">5 scrapy的中间件（下载中间件）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-selenium在scrapy中的使用流程"><span class="toc-text">6 selenium在scrapy中的使用流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-去重规则源码分析"><span class="toc-text">7 去重规则源码分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-分布式爬虫（scrapy-redis）"><span class="toc-text">8 分布式爬虫（scrapy-redis）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-破解知乎登陆-js逆向和解密"><span class="toc-text">9 破解知乎登陆(js逆向和解密)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-爬虫的反扒措施"><span class="toc-text">10 爬虫的反扒措施</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/django-csrf%20%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0/">django-csrf 跨站请求伪造</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/%E5%89%8D%E7%AB%AF%E4%B9%8BCSS/">前端之CSS</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/django-cookie%20%E5%92%8Csession/">django-cookie 和session</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/mysql-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/">mysql-存储引擎</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/django-%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5/">django-批量插入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/%E7%94%B1django%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%BC%95%E5%8F%91%E7%9A%84%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/">由django中间件引发的编程思想</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/05/bbs/">bbs</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/05/django-%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%AC%94%E8%AE%B0/">django-中间件笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/10/%E5%90%84%E7%A7%8D%E7%BD%91%E7%AB%99%E7%9A%84%E7%88%AC%E5%8F%96/">各种网站的爬取</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/08/srapy%E7%9A%84%E9%AB%98%E7%BA%A7%E4%BD%BF%E7%94%A8/">srapy的高级使用</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/drf/" style="font-size: 15px;">drf</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 15px;">爬虫</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/">2018</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/">2017</a><span class="archive-list-count">20</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">Simple.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/" target="_blank" rel="noopener"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?c5fd96eee1193585be191f318c3fa725";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/search.json.js?v=2.0.5"></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>