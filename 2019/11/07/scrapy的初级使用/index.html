<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.5"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><link rel="stylesheet" type="text/css" href="https://unpkg.com/gitalk/dist/gitalk.css?v=2.0.5"><title>scrapy的初级使用 | Simple</title><meta name="generator" content="Hexo 4.2.1"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">scrapy的初级使用</h1><a id="logo" href="/.">Simple</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">scrapy的初级使用</h1><div class="post-meta"><a href="/2019/11/07/scrapy%E7%9A%84%E5%88%9D%E7%BA%A7%E4%BD%BF%E7%94%A8/#comments" class="comment-count"></a><p><span class="date">Nov 07, 2019</span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h2 id="scrapy"><a href="#scrapy" class="headerlink" title="scrapy"></a>scrapy</h2><h2 id="scrapy框架介绍"><a href="#scrapy框架介绍" class="headerlink" title="scrapy框架介绍"></a>scrapy框架介绍</h2><p>执行流程的五大组件</p>
<ul>
<li>引擎(EGINE)：大总管，负责控制数据的流向、</li>
<li>调度器(SCHEDULER)：由它来决定下一个要抓取的网址是什么，去重</li>
<li>下载器(DOWLOADER)：用于下载网页内容, 并将网页内容返回给EGINE，下载器是建立在twisted这个高效的异步模型上的</li>
<li>爬虫(SPIDERS):开发人员自定义的类，用来解析responses，并且提取items，或者发送新的请求request</li>
<li>项目管道(ITEM PIPLINES):在items被提取后负责处理它们，主要包括清理、验证、持久化（比如存到数据库）等操作</li>
</ul>
<p>两大中间件</p>
<ul>
<li>爬虫中间件：位于EGINE和SPIDERS之间，主要工作是处理SPIDERS的输入和输出（用的很少</li>
</ul>
<h2 id="scrapy的安装"><a href="#scrapy的安装" class="headerlink" title="scrapy的安装"></a>scrapy的安装</h2><ul>
<li><p>pip install scrapy</p>
</li>
<li><p>windows上安装不成按照下面的步骤</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1、pip3 install wheel #安装后，便支持通过wheel文件安装软件，wheel文件官网：https:&#x2F;&#x2F;www.lfd.uci.edu&#x2F;~gohlke&#x2F;pythonlibs</span><br><span class="line">3、pip3 install lxml</span><br><span class="line">4、pip3 install pyopenssl</span><br><span class="line">5、下载并安装pywin32：https:&#x2F;&#x2F;sourceforge.net&#x2F;projects&#x2F;pywin32&#x2F;files&#x2F;pywin32&#x2F;</span><br><span class="line">6、下载twisted的wheel文件：http:&#x2F;&#x2F;www.lfd.uci.edu&#x2F;~gohlke&#x2F;pythonlibs&#x2F;#twisted</span><br><span class="line">7、执行pip3 install 下载目录\Twisted-17.9.0-cp36-cp36m-win_amd64.whl</span><br><span class="line">8、pip3 install scrapy</span><br><span class="line"># 3 就有scrapy命令</span><br><span class="line">	-D:\Python36\Scripts\scrapy.exe  用于创建项目</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h2 id="scrapy-创建项目，爬虫，运行"><a href="#scrapy-创建项目，爬虫，运行" class="headerlink" title="scrapy 创建项目，爬虫，运行"></a>scrapy 创建项目，爬虫，运行</h2><ul>
<li><p>创建项目名字<code>scrapy startproject firstscrapy</code></p>
</li>
<li><p>创建爬虫<code>scrapy genspider chouti dig.chouti.com</code></p>
</li>
<li><p>运行<code>scrapy crawl chouti</code>带运行日志。scrapy crawl chouti –nolog  # 不带日志</p>
</li>
<li><p>支持右键执行爬虫,在项目里新建一个main.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute</span><br><span class="line">execute([<span class="string">'scrapy'</span>,<span class="string">'crawl'</span>,<span class="string">'chouti'</span>,<span class="string">'--nolog'</span>])</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h2 id="settings-介绍"><a href="#settings-介绍" class="headerlink" title="settings 介绍"></a>settings 介绍</h2><p>在默认的情况下，scrapy会去遵循爬虫协议会，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> 修改配置文件参数，强行爬取，不遵循协议</span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br><span class="line"><span class="number">2</span> USER_AGENT = <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36'</span></span><br><span class="line"><span class="number">3</span> LOG_LEVEL=<span class="string">'ERROR'</span></span><br></pre></td></tr></table></figure>

<h2 id="scrapy的数据解析"><a href="#scrapy的数据解析" class="headerlink" title="scrapy的数据解析"></a>scrapy的数据解析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#xpath：</span></span><br><span class="line">-response.xpath(<span class="string">'//a[contains(@class,"link-title")]/text()'</span>).extract()  <span class="comment"># 取文本</span></span><br><span class="line">-response.xpath(<span class="string">'//a[contains(@class,"link-title")]/@href'</span>).extract()  <span class="comment">#取属性</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#css</span></span><br><span class="line">-response.css(<span class="string">'.link-title::text'</span>).extract()  <span class="comment"># 取文本</span></span><br><span class="line">    -response.css(<span class="string">'.link-title:: ).extract_first()  # 取属性</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="comment"># title = response.css('.link-title')</span></span><br><span class="line">    <span class="comment"># title = response.xpath('//a[contains(@class,"link-title")]/text()').extract()</span></span><br><span class="line"></span><br><span class="line">    div_list = response.xpath(<span class="string">'//div[contains(@class,"link-item")]'</span>)</span><br><span class="line">    <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">        <span class="comment"># title = div.css('.link-title::text').extract()[0]</span></span><br><span class="line">        url = div.xpath(<span class="string">'//a[contains(@class,"link-title")]/@href'</span>).extract_first()</span><br><span class="line"></span><br><span class="line">        print(url)</span><br></pre></td></tr></table></figure>





<h2 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h2><p>方式一：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">       ll= []</span><br><span class="line">       div_list = response.xpath(<span class="string">'//div[contains(@class,"link-item")]'</span>)</span><br><span class="line">       <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">           title = div.css(<span class="string">'.link-title::text'</span>).extract_first()</span><br><span class="line">           url = div.css(<span class="string">'.link-title::attr(href)'</span>).extract_first()</span><br><span class="line">           img_url = div.css(<span class="string">'.image-scale::attr(src)'</span>).extract_first()</span><br><span class="line">           <span class="comment"># print(img_url) # 必须列表套字典</span></span><br><span class="line">           ll.append((&#123;<span class="string">'title'</span>:title,<span class="string">'url'</span>:url,<span class="string">'img_url'</span>:img_url&#125;))</span><br><span class="line">           <span class="comment"># 数据持久化</span></span><br><span class="line">       <span class="keyword">return</span> ll</span><br></pre></td></tr></table></figure>

<p>方式二：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1 在items中写一个类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChouTiitem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    img_url = scrapy.Field()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 在spinder中导入，实例化把数据放进去</span></span><br><span class="line">			item = ChouTiitem()</span><br><span class="line">            item[<span class="string">'title'</span>] = title</span><br><span class="line">            item[<span class="string">'url'</span>] = url</span><br><span class="line">            item[<span class="string">'img_url'</span>] = img_url</span><br><span class="line">            <span class="comment"># 数据持久化</span></span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 在setting中配置（数字越小，级别越高）</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="comment"># 'app01.pipelines.App01Pipeline': 300,</span></span><br><span class="line">   <span class="string">'app01.pipelines.ChouTiPipeline'</span>: <span class="number">302</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 在pipelines.py中写ChoutiFilePipeline</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChouTiPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        print(<span class="string">'我开了'</span>)</span><br><span class="line">        self.file = open(<span class="string">'chouti.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.file.write(item[<span class="string">'title'</span>] + <span class="string">'\n'</span>)</span><br><span class="line">        self.file.write(item[<span class="string">'url'</span>] + <span class="string">'\n'</span>)</span><br><span class="line">        self.file.write(item[<span class="string">'img_url'</span>] + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        print(<span class="string">'我馆了'</span>)</span><br><span class="line">        self.file.close()</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"> 在pipelines.py中写ChoutiFilePipeline</span><br><span class="line">    	-open_spider（开始的时候）</span><br><span class="line">        -close_spider（结束的时候）</span><br><span class="line">        -process_item（在这持久化）</span><br></pre></td></tr></table></figure>

<p>存在数据库中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChoutiMysqlPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        self.conn=pymysql.connect( host=<span class="string">'127.0.0.1'</span>, user=<span class="string">'root'</span>, password=<span class="string">"123"</span>,</span><br><span class="line">                 database=<span class="string">'chouti'</span>, port=<span class="number">3306</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        self.conn.close()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        cursor=self.conn.cursor()</span><br><span class="line">        sql=<span class="string">'insert into article (title,url,photo_url)values(%s,%s,%s) '</span></span><br><span class="line">        cursor.execute(sql,[item[<span class="string">'title'</span>],item[<span class="string">'url'</span>],item[<span class="string">'photo_url'</span>]])</span><br><span class="line">        self.conn.commit()</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

</div><div class="post-copyright"><blockquote><p>原文作者: Simple</p><p>原文链接: <a href="http://yoursite.com/2019/11/07/scrapy的初级使用/">http://yoursite.com/2019/11/07/scrapy的初级使用/</a></p><p>版权声明: 转载请注明出处(必须保留作者署名及链接)</p></blockquote></div><div class="tags"><a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/2019/11/07/xpath/" class="pre">xpath</a><a href="/2019/11/06/1.%20%E7%88%AC%E8%99%ABrequests%E6%A8%A1%E5%9D%97/" class="next">爬虫requests模块</a></div><div id="comments"><div id="container"><script type="text/javascript" src="https://unpkg.com/gitalk/dist/gitalk.min.js?v=2.0.5"></script><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=2.0.5"></script><script>var gitalk = new Gitalk({
  clientID: '0166bf5540dd89613207',
  clientSecret: '3c34e343b2e8c0f24c9e069e9874e2a661bdd7a3',
  repo: 'git@github.com:zc117809/comment.git',
  owner: 'zc117809',
  admin: ['zc117809'],
  id: md5(window.location.pathname),
  distractionFreeMode: false,
  language: 'zh-CN',
  pagerDirection: 'last'
})
gitalk.render('container')</script></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy"><span class="toc-text">scrapy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy框架介绍"><span class="toc-text">scrapy框架介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy的安装"><span class="toc-text">scrapy的安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy-创建项目，爬虫，运行"><span class="toc-text">scrapy 创建项目，爬虫，运行</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#settings-介绍"><span class="toc-text">settings 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy的数据解析"><span class="toc-text">scrapy的数据解析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据持久化"><span class="toc-text">数据持久化</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/django-csrf%20%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0/">django-csrf 跨站请求伪造</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/%E5%89%8D%E7%AB%AF%E4%B9%8BCSS/">前端之CSS</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/django-cookie%20%E5%92%8Csession/">django-cookie 和session</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/mysql-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/">mysql-存储引擎</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/django-%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5/">django-批量插入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/09/%E7%94%B1django%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%BC%95%E5%8F%91%E7%9A%84%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/">由django中间件引发的编程思想</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/05/bbs/">bbs</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/05/django-%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%AC%94%E8%AE%B0/">django-中间件笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/10/%E5%90%84%E7%A7%8D%E7%BD%91%E7%AB%99%E7%9A%84%E7%88%AC%E5%8F%96/">各种网站的爬取</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/08/srapy%E7%9A%84%E9%AB%98%E7%BA%A7%E4%BD%BF%E7%94%A8/">srapy的高级使用</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/drf/" style="font-size: 15px;">drf</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 15px;">爬虫</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/">2018</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/">2017</a><span class="archive-list-count">20</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">Simple.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/" target="_blank" rel="noopener"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?c5fd96eee1193585be191f318c3fa725";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/search.json.js?v=2.0.5"></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>